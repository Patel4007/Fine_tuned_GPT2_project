{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2143,"sourceType":"datasetVersion","datasetId":1192}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:31:53.209476Z","iopub.execute_input":"2025-02-11T18:31:53.209772Z","iopub.status.idle":"2025-02-11T18:31:53.525132Z","shell.execute_reply.started":"2025-02-11T18:31:53.209751Z","shell.execute_reply":"2025-02-11T18:31:53.524474Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"def clean(s):\n\n    s = str(s)\n    s = re.sub('\\s\\W', ' ', s)\n    s = re.sub('\\W,]s', ' ', s)\n    s = re.sub(\"\\d+\", \"\", s)\n    s = re.sub('\\s+', ' ', s)\n    s = re.sub('[!@#$_]', '', s)\n    s = s.replace(\"co\", \"\")\n    s = s.replace(\"https\", \"\")\n    s = s.replace(\"[\\w*\", \" \")\n    return s\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:31:55.737556Z","iopub.execute_input":"2025-02-11T18:31:55.738008Z","iopub.status.idle":"2025-02-11T18:31:55.742775Z","shell.execute_reply.started":"2025-02-11T18:31:55.737953Z","shell.execute_reply":"2025-02-11T18:31:55.742012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/news-articles/Articles.csv', encoding='ISO-8859-1')\ndf = df.dropna()\ntext_data = open('Articles.txt', 'w')\nfor idx, item in df.iterrows():\n    article = clean(item[\"Article\"])\n    text_data.write(article)\ntext_data.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:31:59.092432Z","iopub.execute_input":"2025-02-11T18:31:59.092725Z","iopub.status.idle":"2025-02-11T18:31:59.932187Z","shell.execute_reply.started":"2025-02-11T18:31:59.092703Z","shell.execute_reply":"2025-02-11T18:31:59.931248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"from transformers import TextDataset, DataCollatorForLanguageModeling\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nfrom transformers import Trainer, TrainingArguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:32:02.674670Z","iopub.execute_input":"2025-02-11T18:32:02.675019Z","iopub.status.idle":"2025-02-11T18:32:10.099763Z","shell.execute_reply.started":"2025-02-11T18:32:02.674961Z","shell.execute_reply":"2025-02-11T18:32:10.099096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_dataset(file_path, tokenizer, block_size=128):\n    dataset = TextDataset(\n        tokenizer = tokenizer,\n        file_path = file_path,\n        block_size = block_size\n    )\n    return dataset\n\ndef load_data_collator(tokenizer, mlm=False):\n\n    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=mlm)\n    return data_collator\n\ndef train(train_file_path, model_name, output_dir, \n          overwrite_output_dir, per_device_train_batch_size, num_train_epochs, save_steps):\n\n\n    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n    train_dataset = load_dataset(train_file_path, tokenizer)\n    data_collator = load_data_collator(tokenizer)\n\n    tokenizer.save_pretrained(output_dir)\n    \n    model = GPT2LMHeadModel.from_pretrained(model_name)\n    model.save_pretrained(output_dir)\n\n    training_args = TrainingArguments(output_dir = output_dir, overwrite_output_dir=overwrite_output_dir,\n                                     per_device_train_batch_size = per_device_train_batch_size,\n                                     num_train_epochs = num_train_epochs)\n    \n    trainer = Trainer(\n        model = model,\n        args = training_args,\n        data_collator=data_collator,\n        train_dataset=train_dataset\n    )\n\n    trainer.train()\n    trainer.save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:32:15.395728Z","iopub.execute_input":"2025-02-11T18:32:15.396446Z","iopub.status.idle":"2025-02-11T18:32:15.402518Z","shell.execute_reply.started":"2025-02-11T18:32:15.396410Z","shell.execute_reply":"2025-02-11T18:32:15.401762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_file_path = '/kaggle/working/Articles.txt'\n\nmodel_name = 'gpt2'\n\noutput_dir = '/kaggle/working'\n\noverwrite_output_dir = False\n\nper_device_train_batch_size = 8\n\nnum_train_epochs = 5.0\n\nsave_steps = 500","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:32:20.695592Z","iopub.execute_input":"2025-02-11T18:32:20.695892Z","iopub.status.idle":"2025-02-11T18:32:20.699889Z","shell.execute_reply.started":"2025-02-11T18:32:20.695871Z","shell.execute_reply":"2025-02-11T18:32:20.698844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train(\n    train_file_path=train_file_path,\n    model_name=model_name,\n    output_dir=output_dir,\n    overwrite_output_dir=overwrite_output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    num_train_epochs=num_train_epochs,\n    save_steps=save_steps\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Inference","metadata":{}},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:32:24.271559Z","iopub.execute_input":"2025-02-11T18:32:24.271858Z","iopub.status.idle":"2025-02-11T18:32:24.276570Z","shell.execute_reply.started":"2025-02-11T18:32:24.271837Z","shell.execute_reply":"2025-02-11T18:32:24.275842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_model(model_path):\n\n    model = GPT2LMHeadModel.from_pretrained(model_path)\n    return model\n\ndef load_tokenizer(tokenizer_path):\n\n    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n    return tokenizer\n\ndef generate_text(sequence, max_length):\n\n    model_path = '/kaggle/working'\n    model = load_model(model_path)\n    tokenizer = load_tokenizer(model_path)\n    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n    final_outputs = model.generate(\n        ids,\n        do_sample=True,\n        max_length=max_length,\n        pad_token_id=model.config.eos_token_id,\n        top_k=50,\n        top_p=0.95,\n    )\n    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))\n\n\n    \n\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:32:27.581135Z","iopub.execute_input":"2025-02-11T18:32:27.581440Z","iopub.status.idle":"2025-02-11T18:32:27.586667Z","shell.execute_reply.started":"2025-02-11T18:32:27.581420Z","shell.execute_reply":"2025-02-11T18:32:27.585755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sequence = \"Japanese yen today\"\nmax_len = 100\ngenerate_text(sequence, max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T19:00:54.178144Z","iopub.execute_input":"2025-02-11T19:00:54.178444Z","iopub.status.idle":"2025-02-11T19:00:57.614094Z","shell.execute_reply.started":"2025-02-11T19:00:54.178425Z","shell.execute_reply":"2025-02-11T19:00:57.613100Z"}},"outputs":[{"name":"stdout","text":"Japanese yen today is also down to $1.099 on the S&P 500.\n\nFor every dollar lost a year ago, that dollar gain could rise further. As the U.S. market shrinks, Japanese companies, which use the yen to secure investments, could gain a foothold. That kind of money has more potential to boost corporate profits, since the yen is no longer a currency denominated in U.S. dollars.\n\nHowever, the yen still has plenty\n","output_type":"stream"}],"execution_count":42}]}